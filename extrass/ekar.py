# -*- coding: utf-8 -*-
"""ekar.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I-bSZ_NZB60VmuQEYN0vnZhMI0Xiqmoh
"""

import json
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Load the dataset from the JSON file, handling line-by-line JSON objects
def load_ekar_dataset(file_path):
    dataset = []
    with open(file_path, 'r') as f:
        for line in f:
            dataset.append(json.loads(line))
    return dataset

# Load the dataset
file_path = '/mnt/data/validation_ekar.json'  # Update with your actual path
ekar_data = load_ekar_dataset(file_path)

# Print the size of the dataset and a sample entry
print(f"Dataset size: {len(ekar_data)}")
print(ekar_data[0])

# Load the original or pruned model
def load_model(model_path):
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForCausalLM.from_pretrained(model_path).to('cuda')
    if tokenizer.pad_token is None:
        tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})
    model.config.pad_token_id = tokenizer.pad_token_id
    return model, tokenizer

# Evaluate the model
def evaluate_ekar_model(model, tokenizer, dataset):
    y_true = []
    y_pred = []

    for item in dataset:
        question = item['question']
        choices = item['choices']['text']
        correct_answer = item['answerKey']

        scores = []
        for choice in choices:
            # Prepare the input with the question and choice
            input_text = f"{question} {choice}"
            inputs = tokenizer(input_text, return_tensors="pt").to('cuda')

            # Generate the output logits
            with torch.no_grad():
                outputs = model(**inputs)

            # Calculate the score (likelihood) for the choice
            logits = outputs.logits[:, :-1, :]
            target_ids = inputs['input_ids'][:, 1:]
            loss_fct = torch.nn.CrossEntropyLoss(reduction='none')
            loss = loss_fct(logits.permute(0, 2, 1), target_ids)
            score = -loss.sum().item()  # Negative log-likelihood as the score
            scores.append(score)

        # Select the choice with the highest score
        predicted_index = torch.argmax(torch.tensor(scores)).item()

        # Append true and predicted labels
        y_true.append(correct_answer)
        y_pred.append(['A', 'B', 'C', 'D'][predicted_index])

    # Calculate metrics
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='weighted')
    recall = recall_score(y_true, y_pred, average='weighted')
    f1 = f1_score(y_true, y_pred, average='weighted')

    return accuracy, precision, recall, f1

# Load and evaluate the original model
original_model_path = 'model_name_or_path'  # Replace with your actual model path
original_model, original_tokenizer = load_model(original_model_path)
accuracy, precision, recall, f1 = evaluate_ekar_model(original_model, original_tokenizer, ekar_data)

print(f"e-KAR Evaluation Metrics:")
print(f"Accuracy: {accuracy * 100:.2f}%")
print(f"Precision: {precision * 100:.2f}%")
print(f"Recall: {recall * 100:.2f}%")
print(f"F1-Score: {f1 * 100:.2f}%")

